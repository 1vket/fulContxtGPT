
model:
  conv_embd: True
  n_kernel: 5
  n_stride: 1
  n_pad: 4
  n_embd: 512
  n_head: 8
  n_layer: 16
  embd_pdrop: 0.1
  attn_pdrop: 0.1
  resid_pdrop: 0.1
  vocab_size: 48
  block_size: 1024
  pad_idx: 0
  sos_idx: 7
  eos_idx: 3
  max_length: 1024

train:
  max_epochs: 50
  batch_size: 8
  learning_rate: 0.0003
  betas: [0.9, 0.95]
  grad_norm_clip: 1.0
  weight_decay: 0.1
  lr_decay: True
  warmup_tokens: 16000000
  final_tokens: 130000000

  ckpt_path: "bestmodel"
  num_workers: 0

